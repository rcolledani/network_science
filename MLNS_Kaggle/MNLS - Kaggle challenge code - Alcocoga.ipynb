{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_team_alcocoga.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RymJ0ynoGnCK",
        "WWjJ2g1AGqk-",
        "pPUkfjo2V3Hz",
        "A0vxUn_FxVr4",
        "DfLCBuukxYtV",
        "xBv_7BKOxa8y",
        "XCSPtqWcxdrm",
        "Sn_jm5SPxgcX",
        "hO52teOKxjuG",
        "jasp8ZXK0osN",
        "FGCBXhuG1ob3",
        "2v4u_v_g1_vm",
        "if0l2FIP2dn6"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I9_8aJN9XIN",
        "outputId": "563124d3-8c4a-4329-c198-cd4221cecbaa"
      },
      "source": [
        "!python -m spacy download en_core_web_lg "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp37-none-any.whl size=829180944 sha256=d66ce5a0e646ac80b9f419916136a825dcce13319d88a963fb69b1e69b140162\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w3wn4dd4/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsEbfAT49jTj",
        "outputId": "c7164689-9006-41b1-ebc1-9293220b2952"
      },
      "source": [
        "!pip install jgraph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jgraph\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/31/b15d3d9407db73a2227fe19fc684b66859ed30f67606b397fa9dabd804b3/jgraph-0.2.1-py2.py3-none-any.whl (119kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 10.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jgraph) (5.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jgraph) (54.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->jgraph) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jgraph) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jgraph) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jgraph) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->jgraph) (5.0.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jgraph) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jgraph) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jgraph) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jgraph) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->jgraph) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->jgraph) (0.7.0)\n",
            "Installing collected packages: jgraph\n",
            "Successfully installed jgraph-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBUWmDGa681X"
      },
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import random\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import jgraph\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn import preprocessing\n",
        "import nltk\n",
        "import csv\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0_osWK7JA8m",
        "outputId": "1a371b73-2d82-44c6-d6ed-eab852aa380b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/MLNS/Kaggle/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGijNJwV7WGo"
      },
      "source": [
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqyQhPtJVh1X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6thdqlJ7XC_"
      },
      "source": [
        "#loading training csv\n",
        "training = pd.read_csv(path+'training_set.txt', \n",
        "                       sep = ' ', header = None) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKY0aDu67XFj"
      },
      "source": [
        "#loading node information data and naming the columns\n",
        "\n",
        "node_info = pd.read_csv(path+'node_information.csv', header= None)\n",
        "node_info.columns = ['id', 'pub_year', 'title', 'authors', 'journal_name', 'abstract']\n",
        "node_info = node_info.set_index('id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQlQUNRK7XIP",
        "outputId": "70bb82dc-9de4-45d4-aad3-2f66bb553d43"
      },
      "source": [
        "#creating the graph network - nodes and edges\n",
        "IDs = [node_id for node_id in node_info.index]\n",
        "\n",
        "training_list = training.values.tolist() # training dataframe convertion for easy edges list comprehension below\n",
        "edges = [(node_pair[0], node_pair[1]) for node_pair in training_list if node_pair[2] == 1]\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(IDs)\n",
        "G.add_edges_from(edges)\n",
        "\n",
        "print(\"Number of nodes : \" + str(G.number_of_nodes()))\n",
        "print(\"Number of edges : \" + str(G.number_of_edges()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of nodes : 27770\n",
            "Number of edges : 335130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwzixk_2U_P8"
      },
      "source": [
        "## Training features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsZgdxej7XNM",
        "outputId": "73052b81-7c53-4d1e-bab9-e7e8d7c37d88"
      },
      "source": [
        "#subsetting the training set to facilitate computation on laptop\n",
        "\n",
        "training_reduced = training.sample(frac=0.1) # We keep 7%\n",
        "training_reduced.columns = ['source', 'target', 'Y']\n",
        "\n",
        "len(training_reduced)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61551"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvSZDP717XR0"
      },
      "source": [
        "# Degree Centrality features\n",
        "out_degree_centrality = nx.out_degree_centrality(G)\n",
        "in_degree_centrality = nx.in_degree_centrality(G)\n",
        "total_centrality = nx.degree_centrality(G)\n",
        "training_reduced['source_out_centrality'] = training_reduced.apply(lambda row: out_degree_centrality[row.source],axis=1)\n",
        "training_reduced['target_in_centrality'] = training_reduced.apply(lambda row: in_degree_centrality[row.target],axis=1)\n",
        "training_reduced['source_centrality'] = training_reduced.apply(lambda row: total_centrality[row.source],axis=1)\n",
        "training_reduced['target_centrality'] = training_reduced.apply(lambda row: total_centrality[row.target],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqrAMi77XWf"
      },
      "source": [
        "eigen_centrality = nx.eigenvector_centrality(G)\n",
        "training_reduced['source_evc'] = training_reduced.apply(lambda row: eigen_centrality[row.source],axis=1)\n",
        "training_reduced['target_evc'] = training_reduced.apply(lambda row: eigen_centrality[row.target],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY_imgnO7XZQ"
      },
      "source": [
        "# Page rank\n",
        "page_rank = nx.pagerank_scipy(G)\n",
        "training_reduced['target_pagerank'] = training_reduced.apply(lambda row: page_rank[row.target],axis=1)\n",
        "\n",
        "# Preferential Attachment\n",
        "# For a directed graph, is equal to K_out_source * K_in_target with K the number of neighbors. Which is equivalent to multiply the available centralities.\n",
        "training_reduced['preferencial_attachment'] = training_reduced.apply(lambda row: row.source_out_centrality * row.target_in_centrality,axis=1)\n",
        "\n",
        "# HITS algorithm\n",
        "hub_score, authority_score = nx.hits(G)\n",
        "training_reduced['source_hub_score'] = training_reduced.apply(lambda row: hub_score[row.source],axis=1)\n",
        "training_reduced['target_authority_score'] = training_reduced.apply(lambda row: authority_score[row.target],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC_zfgn07Xfz"
      },
      "source": [
        "#feature engineering on node attributes - based on node information like title, abstract, published date\n",
        "\n",
        "#difference in publication year\n",
        "\n",
        "training_reduced['pub_year_difference'] = training_reduced.apply(lambda row: node_info.pub_year[row.source] - node_info.pub_year[row.target] ,axis=1)\n",
        "training_reduced['pub_year_difference']=training_reduced['pub_year_difference'].where(training_reduced['pub_year_difference'] >= 0, -1)\n",
        "\n",
        "# common Authors\n",
        "node_info['authors'] = node_info['authors'].fillna(value='')\n",
        "training_reduced['common_authors'] = training_reduced.apply(lambda row: len(set(node_info.authors[row.source].split(\",\")).intersection(set(node_info.authors[row.target].split(\",\")))) ,axis=1)\n",
        "\n",
        "#number of common journal name\n",
        "node_info['journal_name'] = node_info['journal_name'].fillna(value='')\n",
        "training_reduced['common_journals'] = training_reduced.apply(lambda row: len(set(node_info.journal_name[row.source]).intersection(set(node_info.journal_name[row.target]))) ,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpOFf7-67Xig",
        "outputId": "757c364f-d9a1-4907-cbaf-fd179a6e2ed0"
      },
      "source": [
        "# Title similarity-spacy\n",
        "training_reduced['title_similarity'] = training_reduced.apply(lambda row: nlp(node_info.title[row.source]).similarity(nlp(node_info.title[row.target])) ,axis=1)\n",
        "\n",
        "# Abstract similarity- spacy\n",
        "training_reduced['abstract_similarity'] = training_reduced.apply(lambda row: nlp(node_info.abstract[row.source]).similarity(nlp(node_info.abstract[row.target])) ,axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfiYdoE978fP",
        "outputId": "f937b62d-0858-4f98-fa51-13894732c5c4"
      },
      "source": [
        "#cosine distance of abstracts - tf-idf\n",
        "\n",
        "\n",
        "nltk.download('punkt') # for tokenization\n",
        "nltk.download('stopwords')\n",
        "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "\n",
        "\n",
        "\n",
        "def tfidf_abstract():\n",
        "\n",
        "    tfidf_abstracts = []\n",
        "\n",
        "    for i in range(len(node_info)):\n",
        "        abstract = node_info.iloc[i]['abstract'].lower().split(\" \")\n",
        "        abstract = [token for token in abstract if token not in stpwds]\n",
        "        abstract = [stemmer.stem(token) for token in abstract]\n",
        "        tfidf_abstracts.append(\" \".join(abstract))\n",
        "\n",
        "    vectorizer = TfidfVectorizer(min_df=2)\n",
        "    tfidf_abstracts = vectorizer.fit_transform(tfidf_abstracts)\n",
        "\n",
        "    tfidf_abstracts = tfidf_abstracts.toarray()\n",
        "\n",
        "    return tfidf_abstracts\n",
        "\n",
        "tfidf_abstracts = tfidf_abstract()\n",
        "\n",
        "\n",
        "training_distance_abs = []\n",
        "    \n",
        "for i in range(len(training_reduced)):\n",
        "    source = training_reduced.iloc[i]['source']\n",
        "    target = training_reduced.iloc[i]['target']\n",
        "\n",
        "    index_source = IDs.index(source)\n",
        "    index_target = IDs.index(target)\n",
        "\n",
        "    source_info = tfidf_abstracts[index_source].reshape(1, -1)\n",
        "    target_info = tfidf_abstracts[index_target].reshape(1, -1)\n",
        "\n",
        "    training_distance_abs.append(pairwise_distances(source_info, target_info, metric='cosine', n_jobs=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j-TUcsE78l-"
      },
      "source": [
        "training_distance_abs2 = (np.asarray(training_distance_abs).reshape(len(training_reduced),1)).tolist()\n",
        "training_distance_abs = [val for sublist in training_distance_abs2 for val in sublist]\n",
        "training_reduced['training_dist_abs']=training_distance_abs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Taw1ladX78of"
      },
      "source": [
        "#coside distance for titles - tf-idf\n",
        "\n",
        "def tfidf_title():\n",
        "\n",
        "    tfidf_title = []\n",
        "\n",
        "    for i in range(len(node_info)):\n",
        "        title = node_info.iloc[i]['title'].lower().split(\" \")\n",
        "        title = [token for token in title if token not in stpwds]\n",
        "        title = [stemmer.stem(token) for token in title]\n",
        "        tfidf_title.append(\" \".join(title))\n",
        "\n",
        "    vectorizer = TfidfVectorizer(min_df=2)\n",
        "    tfidf_title = vectorizer.fit_transform(tfidf_title)\n",
        "\n",
        "    tfidf_title = tfidf_title.toarray()\n",
        "\n",
        "    return tfidf_title\n",
        "\n",
        "tfidf_title = tfidf_title()\n",
        "\n",
        "\n",
        "training_distance_title = []\n",
        "    \n",
        "for i in range(len(training_reduced)):\n",
        "    source = training_reduced.iloc[i]['source']\n",
        "    target = training_reduced.iloc[i]['target']\n",
        "\n",
        "    index_source = IDs.index(source)\n",
        "    index_target = IDs.index(target)\n",
        "\n",
        "    source_info = tfidf_title[index_source].reshape(1, -1)\n",
        "    target_info = tfidf_title[index_target].reshape(1, -1)\n",
        "\n",
        "    training_distance_title.append(pairwise_distances(source_info, target_info, metric='cosine', n_jobs=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qIW16AY78rD"
      },
      "source": [
        "training_distance_title2=(np.asarray(training_distance_title).reshape(len(training_reduced),1)).tolist()\n",
        "training_distance_title = [val for sublist in training_distance_title2 for val in sublist]\n",
        "training_reduced['training_dist_title']=training_distance_title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzZNgpL278tb"
      },
      "source": [
        "training_reduced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOZAb3my78w2"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "out = defaultdict(list)\n",
        "inc = defaultdict(list)\n",
        "for i, j in edges:\n",
        "    out[i].append(j)\n",
        "    inc[j].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZZijuoe7XlR"
      },
      "source": [
        "def jaccard(source, target):\n",
        "    try:\n",
        "        denom = 1/len(set(out[source]) | set(inc[target]))\n",
        "    except:\n",
        "        denom = 1\n",
        "    jac = len(set(out[source]) & set(inc[target]))*denom\n",
        "    return jac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aocW2r_U7Xn0"
      },
      "source": [
        "\n",
        "def comonneighbors(source, target):\n",
        "    source = set(out[source]) | set(inc[source])\n",
        "    target = set(out[target]) | set(inc[target])\n",
        "    return len(target & source)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fxWVkKY7Xqq"
      },
      "source": [
        "#jaccard\n",
        "\n",
        "ls=[]\n",
        "for i in range(training_reduced.shape[0]):\n",
        "    ls.append(jaccard(training_reduced.iloc[i]['source'], training_reduced.iloc[i]['target']))\n",
        "training_reduced['jacard'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ex2jDP7XtD"
      },
      "source": [
        "#common neighbors\n",
        "\n",
        "ls = [] \n",
        "for i in range(training_reduced.shape[0]):\n",
        "    ls.append(comonneighbors(training_reduced.iloc[i]['source'], training_reduced.iloc[i]['target']))\n",
        "training_reduced['comonneigh'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMqGCjOY7XvS"
      },
      "source": [
        "#in neighbors\n",
        "#out neighbors\n",
        "\n",
        "ls1=[]\n",
        "ls2=[]\n",
        "for i in range(training_reduced.shape[0]):\n",
        "    ls1.append(len(out[training_reduced.iloc[i]['source']]))\n",
        "    ls2.append(len(inc[training_reduced.iloc[i]['target']]))\n",
        "training_reduced['outneighbors'] = ls1\n",
        "training_reduced['inneighbors'] = ls2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv78qHjn8eGE"
      },
      "source": [
        "#common successors\n",
        "ls=[]\n",
        "for i, rows in training_reduced.iterrows():\n",
        "    ls.append(len(set(out[rows['source']]) & set(out[rows['target']])))\n",
        "training_reduced['common_successors'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcDcoBwO8eI4"
      },
      "source": [
        "#common predessesors\n",
        "ls=[]\n",
        "for i, rows in training_reduced.iterrows():\n",
        "    ls.append(len(set(inc[rows['source']]) & set(inc[rows['target']])))\n",
        "training_reduced['common_pred'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wMdLemG8ePG"
      },
      "source": [
        "#number of overlapping words in title\n",
        "def overlapping_title(source, target):\n",
        "    title = node_info.loc[source, 'title']\n",
        "    title = [token for token in title.lower().split(\" \") if token not in stpwds]\n",
        "    source = [stemmer.stem(token) for token in title]\n",
        "    title = node_info.loc[target, 'title']\n",
        "    title = [token for token in title.lower().split(\" \") if token not in stpwds]\n",
        "    target = [stemmer.stem(token) for token in title]    \n",
        "    return len(set(target) & set(source))\n",
        "ls=[]\n",
        "for i, rows in training_reduced.iterrows():\n",
        "    ls.append(overlapping_title(rows['source'], rows['target']))\n",
        "\n",
        "training_reduced['overlap_title'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tq5f0Ye8eSF"
      },
      "source": [
        "#number of overlapping words( >= 9 letters) in abstracts\n",
        "def overlapping_abstract(source, target):\n",
        "    abstract = node_info.loc[source, 'abstract']\n",
        "    abstract = [token for token in abstract.lower().split(\" \") if token not in stpwds and len(token)>8]\n",
        "    source = [stemmer.stem(token) for token in abstract]\n",
        "    abstract = node_info.loc[target, 'abstract']\n",
        "    abstract = [token for token in abstract.lower().split(\" \") if token not in stpwds and len(token)>8]\n",
        "    target = [stemmer.stem(token) for token in abstract]    \n",
        "    return len(set(target) & set(source))\n",
        "ls=[]\n",
        "for i, rows in training_reduced.iterrows():\n",
        "    ls.append(overlapping_abstract(rows['source'], rows['target']))\n",
        "\n",
        "training_reduced['overlap_abstract'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXvG45LM8eUw"
      },
      "source": [
        "#paths of length one\n",
        "ls=[]\n",
        "for i, rows in training_reduced.iterrows():\n",
        "    try:\n",
        "        short_path = nx.shortest_path_length(G,source=rows['source'],target=rows['target'])\n",
        "    except:\n",
        "        short_path = -1\n",
        "    ls.append(short_path)\n",
        "training_reduced['short_path'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIeQ8P8-8pY9"
      },
      "source": [
        "\n",
        "#popularity\n",
        "ls=[]\n",
        "for i, rows in training_reduced.iterrows():\n",
        "    ls.append(sum([len(inc[in_target]) for in_target in inc[rows['target']]]))\n",
        "training_reduced['popularity'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjLX3u5DUQpx",
        "outputId": "8efd8a60-f42a-41bc-f046-9151d5a28ca3"
      },
      "source": [
        "#loading node information data and naming the columns\n",
        "node_info = pd.read_csv(path+'node_information.csv', header= None)\n",
        "node_info.columns = ['id', 'pub_year', 'title', 'authors', 'journal_name', 'abstract']\n",
        "node_info = node_info.set_index('id')\n",
        "\n",
        "#creating the graph network - nodes and edges\n",
        "IDs = [node_id for node_id in node_info.index]\n",
        "\n",
        "training_list = training.values.tolist() # training dataframe convertion for easy edges list comprehension below\n",
        "edges = [(node_pair[0], node_pair[1]) for node_pair in training_list if node_pair[2] == 1]\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(IDs)\n",
        "G.add_edges_from(edges)\n",
        "\n",
        "print(\"Number of nodes : \" + str(G.number_of_nodes()))\n",
        "print(\"Number of edges : \" + str(G.number_of_edges()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of nodes : 27770\n",
            "Number of edges : 335130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLwl2MhMG_IC"
      },
      "source": [
        "# Preferential attachement\n",
        "La = list(G.degree(training_reduced['target']))\n",
        "Lb = list(G.degree(training_reduced['target']))\n",
        "\n",
        "PA = [a[1]*b[1] for a,b in zip(La,Lb)]\n",
        "training_reduced['PA'] = PA\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4YPqWKaKSdf"
      },
      "source": [
        "#AdamicAdar\n",
        "G_prime = G.to_undirected()\n",
        "AdamicAdar = []\n",
        "\n",
        "for i in range(len(training_reduced)):\n",
        "  #  print(i)\n",
        "    inter_list = nx.common_neighbors(G_prime, training_reduced['source'][i], training_reduced['target'][i])\n",
        "    AdamicAdar.append(sum( [1/np.log(G_prime.degree(node)) for node in inter_list]))\n",
        "\n",
        "training_reduced['AdamicAdar'] = AdamicAdar\n",
        "\n",
        "\n",
        "#Standardize values if needed\n",
        "training_reduced['AA_std'] = (training_reduced['AdamicAdar']-training_reduced['AdamicAdar'].mean())/training_reduced['AdamicAdar'].std()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZtJiN8iSkGK"
      },
      "source": [
        "nx.common_neighbors(G_prime, training_reduced['source'][0], training_reduced['target'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "CzuxKuz88pbi",
        "outputId": "24f977b9-c948-41a5-9675-bac070591dd3"
      },
      "source": [
        "training_reduced"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>Y</th>\n",
              "      <th>source_out_centrality</th>\n",
              "      <th>target_in_centrality</th>\n",
              "      <th>source_centrality</th>\n",
              "      <th>target_centrality</th>\n",
              "      <th>source_evc</th>\n",
              "      <th>target_evc</th>\n",
              "      <th>target_pagerank</th>\n",
              "      <th>preferencial_attachment</th>\n",
              "      <th>source_hub_score</th>\n",
              "      <th>target_authority_score</th>\n",
              "      <th>pub_year_difference</th>\n",
              "      <th>common_authors</th>\n",
              "      <th>common_journals</th>\n",
              "      <th>title_similarity</th>\n",
              "      <th>abstract_similarity</th>\n",
              "      <th>training_dist_abs</th>\n",
              "      <th>training_dist_title</th>\n",
              "      <th>jacard</th>\n",
              "      <th>comonneigh</th>\n",
              "      <th>outneighbors</th>\n",
              "      <th>inneighbors</th>\n",
              "      <th>common_successors</th>\n",
              "      <th>common_pred</th>\n",
              "      <th>overlap_title</th>\n",
              "      <th>overlap_abstract</th>\n",
              "      <th>short_path</th>\n",
              "      <th>popularity</th>\n",
              "      <th>PA</th>\n",
              "      <th>AdamicAdar</th>\n",
              "      <th>AA_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201268</td>\n",
              "      <td>106086</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001008</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>0.001332</td>\n",
              "      <td>0.001873</td>\n",
              "      <td>3.225356e-10</td>\n",
              "      <td>2.160483e-08</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>7.625298e-07</td>\n",
              "      <td>4.162079e-05</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.599307</td>\n",
              "      <td>0.932746</td>\n",
              "      <td>0.698262</td>\n",
              "      <td>0.830163</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>15</td>\n",
              "      <td>28</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>291</td>\n",
              "      <td>2704</td>\n",
              "      <td>3.383829</td>\n",
              "      <td>0.623655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>303245</td>\n",
              "      <td>9912249</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>0.006950</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>0.007670</td>\n",
              "      <td>2.216651e-38</td>\n",
              "      <td>6.815509e-07</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>6.757726e-06</td>\n",
              "      <td>8.724021e-06</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.588809</td>\n",
              "      <td>0.943256</td>\n",
              "      <td>0.953734</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.028037</td>\n",
              "      <td>6</td>\n",
              "      <td>27</td>\n",
              "      <td>193</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5550</td>\n",
              "      <td>45369</td>\n",
              "      <td>1.218342</td>\n",
              "      <td>-0.094395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>103047</td>\n",
              "      <td>9803167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001368</td>\n",
              "      <td>0.002017</td>\n",
              "      <td>0.001404</td>\n",
              "      <td>0.003637</td>\n",
              "      <td>1.349280e-22</td>\n",
              "      <td>3.696475e-04</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>2.759632e-06</td>\n",
              "      <td>3.389136e-04</td>\n",
              "      <td>0.000566</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0.714307</td>\n",
              "      <td>0.927827</td>\n",
              "      <td>0.961005</td>\n",
              "      <td>0.882550</td>\n",
              "      <td>0.056180</td>\n",
              "      <td>12</td>\n",
              "      <td>38</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2494</td>\n",
              "      <td>10201</td>\n",
              "      <td>2.295006</td>\n",
              "      <td>0.262614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9708168</td>\n",
              "      <td>9903201</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002341</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.003025</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>2.487611e-05</td>\n",
              "      <td>4.310256e-06</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>9.272259e-07</td>\n",
              "      <td>1.203392e-04</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.511467</td>\n",
              "      <td>0.968647</td>\n",
              "      <td>0.868493</td>\n",
              "      <td>0.964800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>292</td>\n",
              "      <td>441</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.498383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9211108</td>\n",
              "      <td>9811043</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>1.993640e-05</td>\n",
              "      <td>2.216651e-38</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.498692</td>\n",
              "      <td>0.942453</td>\n",
              "      <td>0.971903</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.498383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61546</th>\n",
              "      <td>9610004</td>\n",
              "      <td>9607110</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>2.216651e-38</td>\n",
              "      <td>7.113873e-07</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>2.853003e-08</td>\n",
              "      <td>1.970745e-15</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.278649</td>\n",
              "      <td>0.882433</td>\n",
              "      <td>0.967820</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>45</td>\n",
              "      <td>121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.498383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61547</th>\n",
              "      <td>9902137</td>\n",
              "      <td>9601066</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000324</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000864</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>2.858195e-07</td>\n",
              "      <td>2.216651e-38</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.431998e-04</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.665011</td>\n",
              "      <td>0.949547</td>\n",
              "      <td>0.967451</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.498383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61548</th>\n",
              "      <td>9806146</td>\n",
              "      <td>9602064</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001440</td>\n",
              "      <td>0.006194</td>\n",
              "      <td>0.005654</td>\n",
              "      <td>0.007202</td>\n",
              "      <td>1.510618e-05</td>\n",
              "      <td>1.086430e-02</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>8.922118e-06</td>\n",
              "      <td>3.059135e-04</td>\n",
              "      <td>0.000744</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.661409</td>\n",
              "      <td>0.965964</td>\n",
              "      <td>0.695576</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>40</td>\n",
              "      <td>172</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>9010</td>\n",
              "      <td>40000</td>\n",
              "      <td>1.232788</td>\n",
              "      <td>-0.089605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61549</th>\n",
              "      <td>211236</td>\n",
              "      <td>9205110</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>0.001188</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>0.001188</td>\n",
              "      <td>2.031627e-21</td>\n",
              "      <td>3.504871e-04</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>1.369441e-06</td>\n",
              "      <td>2.895063e-05</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.913034</td>\n",
              "      <td>0.950249</td>\n",
              "      <td>0.930183</td>\n",
              "      <td>0.607162</td>\n",
              "      <td>0.065574</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>783</td>\n",
              "      <td>1089</td>\n",
              "      <td>1.319043</td>\n",
              "      <td>-0.061004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61550</th>\n",
              "      <td>110026</td>\n",
              "      <td>9402125</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001621</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>0.001837</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>1.365457e-35</td>\n",
              "      <td>2.901564e-03</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>7.002825e-07</td>\n",
              "      <td>5.473144e-07</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.521510</td>\n",
              "      <td>0.947961</td>\n",
              "      <td>0.984518</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>252</td>\n",
              "      <td>225</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.498383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61551 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        source   target  Y  ...     PA  AdamicAdar    AA_std\n",
              "0       201268   106086  1  ...   2704    3.383829  0.623655\n",
              "1       303245  9912249  1  ...  45369    1.218342 -0.094395\n",
              "2       103047  9803167  1  ...  10201    2.295006  0.262614\n",
              "3      9708168  9903201  0  ...    441    0.000000 -0.498383\n",
              "4      9211108  9811043  0  ...      4    0.000000 -0.498383\n",
              "...        ...      ... ..  ...    ...         ...       ...\n",
              "61546  9610004  9607110  0  ...    121    0.000000 -0.498383\n",
              "61547  9902137  9601066  0  ...      1    0.000000 -0.498383\n",
              "61548  9806146  9602064  1  ...  40000    1.232788 -0.089605\n",
              "61549   211236  9205110  1  ...   1089    1.319043 -0.061004\n",
              "61550   110026  9402125  0  ...    225    0.000000 -0.498383\n",
              "\n",
              "[61551 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jG81bvDsRWA"
      },
      "source": [
        "training_reduced.to_csv(path+'training_reduced_10percent.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdqy6swL8vnf"
      },
      "source": [
        "## Processing on testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5phSKOZ_8pgo"
      },
      "source": [
        "\n",
        "testing = pd.read_csv(path+'testing_set.txt', sep = ' ', header = None)\n",
        "testing.columns = ['source', 'target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VywlIz1Z8pjK"
      },
      "source": [
        "\n",
        "# Degree Centrality features\n",
        "out_degree_centrality = nx.out_degree_centrality(G)\n",
        "in_degree_centrality = nx.in_degree_centrality(G)\n",
        "total_centrality = nx.degree_centrality(G)\n",
        "testing['source_out_centrality'] = testing.apply(lambda row: out_degree_centrality[row.source],axis=1)\n",
        "testing['target_in_centrality'] = testing.apply(lambda row: in_degree_centrality[row.target],axis=1)\n",
        "testing['source_centrality'] = testing.apply(lambda row: total_centrality[row.source],axis=1)\n",
        "testing['target_centrality'] = testing.apply(lambda row: total_centrality[row.target],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdGhc_LY8eXq"
      },
      "source": [
        "#eigen vector centrality\n",
        "eigen_centrality = nx.eigenvector_centrality(G)\n",
        "testing['source_evc'] = testing.apply(lambda row: eigen_centrality[row.source],axis=1)\n",
        "testing['target_evc'] = testing.apply(lambda row: eigen_centrality[row.target],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEQaMqNM84Oq"
      },
      "source": [
        "# Page rank\n",
        "page_rank = nx.pagerank_scipy(G)\n",
        "testing['target_pagerank'] = testing.apply(lambda row: page_rank[row.target],axis=1)\n",
        "\n",
        "# Preferential Attachment\n",
        "# For a directed graph, is equal to K_out_source * K_in_target with K the number of neighbors. Which is equivalent to multiply the available centralities.\n",
        "testing['preferencial_attachment'] = testing.apply(lambda row: row.source_out_centrality * row.target_in_centrality,axis=1)\n",
        "\n",
        "# HITS algorithm\n",
        "hub_score, authority_score = nx.hits(G)\n",
        "testing['source_hub_score'] = testing.apply(lambda row: hub_score[row.source],axis=1)\n",
        "testing['target_authority_score'] = testing.apply(lambda row: authority_score[row.target],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os7sKNsv84R5"
      },
      "source": [
        "\n",
        "#feature engineering on node attributes - based on node information like title, abstract, published date\n",
        "\n",
        "#difference in publication year\n",
        "\n",
        "testing['pub_year_difference'] = testing.apply(lambda row: node_info.pub_year[row.source] - node_info.pub_year[row.target] ,axis=1)\n",
        "testing['pub_year_difference']=testing['pub_year_difference'].where(testing['pub_year_difference'] >= 0, -1)\n",
        "\n",
        "# common Authors\n",
        "node_info['authors'] = node_info['authors'].fillna(value='')\n",
        "testing['common_authors'] = testing.apply(lambda row: len(set(node_info.authors[row.source].split(\",\")).intersection(set(node_info.authors[row.target].split(\",\")))) ,axis=1)\n",
        "\n",
        "#number of common journal name\n",
        "node_info['journal_name'] = node_info['journal_name'].fillna(value='')\n",
        "testing['common_journals'] = testing.apply(lambda row: len(set(node_info.journal_name[row.source]).intersection(set(node_info.journal_name[row.target]))) ,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XYyRlT984U9"
      },
      "source": [
        "# Title\n",
        "testing['title_similarity'] = testing.apply(lambda row: nlp(node_info.title[row.source]).similarity(nlp(node_info.title[row.target])) ,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og6A6hAo84Xo"
      },
      "source": [
        "# Abstract similarity- spacy\n",
        "testing['abstract_similarity'] = testing.apply(lambda row: nlp(node_info.abstract[row.source]).similarity(nlp(node_info.abstract[row.target])) ,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEfZiWfK84aa"
      },
      "source": [
        "#cosine distance - abstract\n",
        "testing_distance_abs = []\n",
        "    \n",
        "for i in range(len(testing)):\n",
        "    source = testing.iloc[i]['source']\n",
        "    target = testing.iloc[i]['target']\n",
        "\n",
        "    index_source = IDs.index(source)\n",
        "    index_target = IDs.index(target)\n",
        "\n",
        "    source_info = tfidf_abstracts[index_source].reshape(1, -1)\n",
        "    target_info = tfidf_abstracts[index_target].reshape(1, -1)\n",
        "\n",
        "    testing_distance_abs.append(pairwise_distances(source_info, target_info, metric='cosine', n_jobs=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqaO0wTX84dZ"
      },
      "source": [
        "testing_distance_abs2 = (np.asarray(testing_distance_abs).reshape(len(testing),1)).tolist()\n",
        "testing_distance_abs = [val for sublist in testing_distance_abs2 for val in sublist]\n",
        "testing['testing_dist_abs']=testing_distance_abs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvK7upkb84f_"
      },
      "source": [
        "#cosine distance- title\n",
        "\n",
        "testing_distance_title = []\n",
        "    \n",
        "for i in range(len(testing)):\n",
        "    source = testing.iloc[i]['source']\n",
        "    target = testing.iloc[i]['target']\n",
        "\n",
        "    index_source = IDs.index(source)\n",
        "    index_target = IDs.index(target)\n",
        "\n",
        "    source_info = tfidf_title[index_source].reshape(1, -1)\n",
        "    target_info = tfidf_title[index_target].reshape(1, -1)\n",
        "\n",
        "    testing_distance_title.append(pairwise_distances(source_info, target_info, metric='cosine', n_jobs=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dR7at_H84if"
      },
      "source": [
        "\n",
        "testing_distance_title2=(np.asarray(testing_distance_title).reshape(len(testing),1)).tolist()\n",
        "testing_distance_title = [val for sublist in testing_distance_title2 for val in sublist]\n",
        "testing['training_dist_title']=testing_distance_title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDmgdZEj84k4"
      },
      "source": [
        "#jaccard\n",
        "\n",
        "ls=[]\n",
        "for i in range(testing.shape[0]):\n",
        "    ls.append(jaccard(testing.iloc[i]['source'], testing.iloc[i]['target']))\n",
        "testing['jacard'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7psCDKIX9aNe"
      },
      "source": [
        "#common neighbors\n",
        "\n",
        "ls = [] \n",
        "for i in range(testing.shape[0]):\n",
        "    ls.append(comonneighbors(testing.iloc[i]['source'], testing.iloc[i]['target']))\n",
        "testing['comonneigh'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5do3LiB9aQN"
      },
      "source": [
        "#in neighbors\n",
        "#out neighbors\n",
        "\n",
        "ls1=[]\n",
        "ls2=[]\n",
        "for i in range(testing.shape[0]):\n",
        "    ls1.append(len(out[testing.iloc[i]['source']]))\n",
        "    ls2.append(len(inc[testing.iloc[i]['target']]))\n",
        "testing['outneighbors'] = ls1\n",
        "testing['inneighbors'] = ls2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd5mhaRG9aTG"
      },
      "source": [
        "#common successors\n",
        "ls=[]\n",
        "for i, rows in testing.iterrows():\n",
        "    ls.append(len(set(out[rows['source']]) & set(out[rows['target']])))\n",
        "testing['common_successors'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86TZ1MX97Xxm"
      },
      "source": [
        "\n",
        "#common predessesors\n",
        "ls=[]\n",
        "for i, rows in testing.iterrows():\n",
        "    ls.append(len(set(inc[rows['source']]) & set(inc[rows['target']])))\n",
        "testing['common_pred'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXVpO7Vb7Xz_"
      },
      "source": [
        "#number of overlapping words in title\n",
        "ls=[]\n",
        "for i, rows in testing.iterrows():\n",
        "    ls.append(overlapping_title(rows['source'], rows['target']))\n",
        "\n",
        "testing['overlap_title'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XzCuQG79kMy"
      },
      "source": [
        "#number of overlapping words( >= 9 letters) in abstracts\n",
        "ls=[]\n",
        "for i, rows in testing.iterrows():\n",
        "    ls.append(overlapping_abstract(rows['source'], rows['target']))\n",
        "\n",
        "testing['overlap_abstract'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi3XI7as9kPe"
      },
      "source": [
        "#paths of length onele]\n",
        "ls=[]\n",
        "for i, rows in testing.iterrows():\n",
        "    try:    \n",
        "        short_path = nx.shortest_path_length(G,source=rows['source'],target=rows['target'])\n",
        "    except:\n",
        "        short_path = -1\n",
        "    if short_path == 1:\n",
        "        G.remove_edge(rows['source'],rows['target'])\n",
        "        try:    \n",
        "            short_path = nx.shortest_path_length(G,source=rows['source'],target=rows['target'])\n",
        "        except:\n",
        "            short_path = -1\n",
        "        G.add_edge(rows['source'],rows['target'])\n",
        "    ls.append(short_path)\n",
        "testing['short_path'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF8PUeY69kR_"
      },
      "source": [
        "#popularity\n",
        "ls=[]\n",
        "for i, rows in testing.iterrows():\n",
        "    ls.append(sum([len(inc[in_target]) for in_target in inc[rows['target']]]))\n",
        "testing['popularity'] = ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvGpae9SRFq1"
      },
      "source": [
        "# Preferential attachement - testing\n",
        "Lc = list(G.degree(testing['target']))\n",
        "Ld = list(G.degree(testing['target']))\n",
        "\n",
        "PA_test = [c[1]*d[1] for c,d in zip(Lc,Ld)]\n",
        "testing['PA'] = PA_test\n",
        "\n",
        "#AdamicAdar - test\n",
        "AdamicAdar_test = []\n",
        "\n",
        "for i in range(len(testing)):\n",
        "  #  print(i)\n",
        "    inter_list = nx.common_neighbors(G_prime, testing['source'][i], testing['target'][i])\n",
        "    AdamicAdar_test.append(sum( [1/np.log(G_prime.degree(node)) for node in inter_list]))\n",
        "\n",
        "testing['AdamicAdar'] = AdamicAdar_test\n",
        "\n",
        "testing['AA_std'] = (testing['AdamicAdar']-testing['AdamicAdar'].mean())/testing['AdamicAdar'].std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "-wGY6I6v9kUm",
        "outputId": "111d6d8a-f3db-46a8-ba09-b8620eaec852"
      },
      "source": [
        "testing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>source_out_centrality</th>\n",
              "      <th>target_in_centrality</th>\n",
              "      <th>source_centrality</th>\n",
              "      <th>target_centrality</th>\n",
              "      <th>source_evc</th>\n",
              "      <th>target_evc</th>\n",
              "      <th>target_pagerank</th>\n",
              "      <th>preferencial_attachment</th>\n",
              "      <th>source_hub_score</th>\n",
              "      <th>target_authority_score</th>\n",
              "      <th>pub_year_difference</th>\n",
              "      <th>common_authors</th>\n",
              "      <th>common_journals</th>\n",
              "      <th>title_similarity</th>\n",
              "      <th>abstract_similarity</th>\n",
              "      <th>testing_dist_abs</th>\n",
              "      <th>training_dist_title</th>\n",
              "      <th>jacard</th>\n",
              "      <th>comonneigh</th>\n",
              "      <th>outneighbors</th>\n",
              "      <th>inneighbors</th>\n",
              "      <th>common_successors</th>\n",
              "      <th>common_pred</th>\n",
              "      <th>overlap_title</th>\n",
              "      <th>overlap_abstract</th>\n",
              "      <th>popularity</th>\n",
              "      <th>short_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9807076</td>\n",
              "      <td>9807139</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.002125</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>9.082262e-06</td>\n",
              "      <td>5.472969e-14</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>3.890458e-08</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>4.201273e-06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.630372</td>\n",
              "      <td>0.945913</td>\n",
              "      <td>0.904748</td>\n",
              "      <td>0.926176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>109162</td>\n",
              "      <td>1182</td>\n",
              "      <td>0.007310</td>\n",
              "      <td>0.001404</td>\n",
              "      <td>0.010911</td>\n",
              "      <td>0.001621</td>\n",
              "      <td>2.993220e-11</td>\n",
              "      <td>3.777396e-07</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>1.026692e-05</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>4.779221e-05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.746081</td>\n",
              "      <td>0.940232</td>\n",
              "      <td>0.821613</td>\n",
              "      <td>0.663806</td>\n",
              "      <td>0.075556</td>\n",
              "      <td>24</td>\n",
              "      <td>203</td>\n",
              "      <td>39</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1266</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9702187</td>\n",
              "      <td>9510135</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.026144</td>\n",
              "      <td>0.008031</td>\n",
              "      <td>0.026612</td>\n",
              "      <td>4.259980e-03</td>\n",
              "      <td>8.746000e-02</td>\n",
              "      <td>0.002588</td>\n",
              "      <td>1.318087e-05</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>3.320411e-03</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0.709009</td>\n",
              "      <td>0.894299</td>\n",
              "      <td>0.862108</td>\n",
              "      <td>0.843365</td>\n",
              "      <td>0.006803</td>\n",
              "      <td>59</td>\n",
              "      <td>14</td>\n",
              "      <td>726</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28210</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>111048</td>\n",
              "      <td>110115</td>\n",
              "      <td>0.001440</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>0.001837</td>\n",
              "      <td>0.002341</td>\n",
              "      <td>1.489686e-10</td>\n",
              "      <td>1.513932e-10</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>8.299645e-07</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>3.620505e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.677584</td>\n",
              "      <td>0.933354</td>\n",
              "      <td>0.857282</td>\n",
              "      <td>0.951234</td>\n",
              "      <td>0.056604</td>\n",
              "      <td>21</td>\n",
              "      <td>40</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>214</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9910176</td>\n",
              "      <td>9410073</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.005186</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.005402</td>\n",
              "      <td>1.032959e-35</td>\n",
              "      <td>5.801489e-02</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>1.120452e-06</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>6.548123e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.777573</td>\n",
              "      <td>0.908490</td>\n",
              "      <td>0.709004</td>\n",
              "      <td>0.916987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8521</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32643</th>\n",
              "      <td>9705209</td>\n",
              "      <td>9305083</td>\n",
              "      <td>0.001368</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.001873</td>\n",
              "      <td>1.494568e-06</td>\n",
              "      <td>2.939870e-02</td>\n",
              "      <td>0.000367</td>\n",
              "      <td>2.316120e-06</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>8.972854e-05</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.912030</td>\n",
              "      <td>0.954891</td>\n",
              "      <td>0.792051</td>\n",
              "      <td>0.574762</td>\n",
              "      <td>0.011905</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1789</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32644</th>\n",
              "      <td>9307023</td>\n",
              "      <td>9503118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>4.822759e-07</td>\n",
              "      <td>1.318309e-08</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.588466e-08</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.660164</td>\n",
              "      <td>0.875399</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32645</th>\n",
              "      <td>9608095</td>\n",
              "      <td>9205058</td>\n",
              "      <td>0.000936</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.001404</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>5.156258e-05</td>\n",
              "      <td>5.108872e-03</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>6.069115e-07</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>1.895048e-05</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.676492</td>\n",
              "      <td>0.932821</td>\n",
              "      <td>0.950765</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32646</th>\n",
              "      <td>9407008</td>\n",
              "      <td>106256</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>0.001404</td>\n",
              "      <td>5.007298e-03</td>\n",
              "      <td>4.114137e-12</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>1.167138e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>5.549531e-06</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.674227</td>\n",
              "      <td>0.946057</td>\n",
              "      <td>0.990748</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32647</th>\n",
              "      <td>208144</td>\n",
              "      <td>7142</td>\n",
              "      <td>0.001080</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>0.000612</td>\n",
              "      <td>1.032959e-35</td>\n",
              "      <td>3.481527e-10</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>1.945229e-07</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.625043e-05</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.611502</td>\n",
              "      <td>0.934458</td>\n",
              "      <td>0.950445</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32648 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        source   target  ...  popularity  short_path\n",
              "0      9807076  9807139  ...           5          16\n",
              "1       109162     1182  ...        1266           2\n",
              "2      9702187  9510135  ...       28210           2\n",
              "3       111048   110115  ...         214           2\n",
              "4      9910176  9410073  ...        8521           3\n",
              "...        ...      ...  ...         ...         ...\n",
              "32643  9705209  9305083  ...        1789           2\n",
              "32644  9307023  9503118  ...           9          -1\n",
              "32645  9608095  9205058  ...         324           3\n",
              "32646  9407008   106256  ...          62          -1\n",
              "32647   208144     7142  ...          24           2\n",
              "\n",
              "[32648 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQykcWpDfoVQ"
      },
      "source": [
        "testing.to_csv(path+\"testinst_full_features.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ESrbTmL6mmJ"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-RH_cJk9kXf"
      },
      "source": [
        "#cutting out few features for trial\n",
        "\n",
        "x_train_cut= training_reduced.drop(['common_journals','source_centrality', 'target_centrality', 'source_evc','target_evc','short_path'], axis= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm6_xcJp9kal"
      },
      "source": [
        "#cutting out few features from test for trial\n",
        "\n",
        "#x_test_cut=testing.drop(['common_journals','source_centrality', 'target_centrality', 'source_evc','target_evc','short_path'], axis= 1)\n",
        "x_test_cut=testing.drop(['common_journals','source_centrality', 'target_centrality', 'source_evc','target_evc'], axis= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ6I5VZZ9kdJ"
      },
      "source": [
        "#Scaling all the features\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "training_reduced_scale= scaler.fit_transform(training_reduced[['source_out_centrality','target_in_centrality',\n",
        "                            'source_centrality','target_centrality','source_evc','target_evc','target_pagerank',\n",
        "                            'preferencial_attachment','source_hub_score','target_authority_score', 'pub_year_difference',\n",
        "                            'common_authors','common_journals','title_similarity','abstract_similarity','training_dist_abs',\n",
        "                            'training_dist_title','jacard','comonneigh','outneighbors','inneighbors','common_successors',\n",
        "                            'common_pred','overlap_title','overlap_abstract','popularity','PA','AA_std']])\n",
        "training_reduced_scale = pd.DataFrame(training_reduced_scale)\n",
        "\n",
        "testing_scale=scaler.fit_transform(testing[['source_out_centrality','target_in_centrality','source_centrality','target_centrality',\n",
        "                                            'source_evc','target_evc','target_pagerank','preferencial_attachment','source_hub_score',\n",
        "                                            'target_authority_score', 'pub_year_difference','common_authors','common_journals',\n",
        "                                            'title_similarity','abstract_similarity','testing_dist_abs','training_dist_title',\n",
        "                                            'jacard','comonneigh','outneighbors','inneighbors','common_successors','common_pred',\n",
        "                                            'overlap_title','overlap_abstract','popularity','PA','AA_std']])\n",
        "testing_scale = pd.DataFrame(testing_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suQHoPYK7X2v"
      },
      "source": [
        "#test train split for actual(unscaled) features\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_train_cut.drop(['source', 'target', 'Y'], axis= 1), training_reduced.Y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KJTFcpc902q",
        "outputId": "67e5274f-de9d-4480-d54c-0e555057acaf"
      },
      "source": [
        "#test train split for scaled features\n",
        "iter = np.arange(0.15,0.35,0.01)\n",
        "scores={}\n",
        "for x in iter:\n",
        "  print('iteration number :',x)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(training_reduced_scale, training_reduced.Y, test_size=x)\n",
        "\n",
        "  mlp = MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
        "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "              hidden_layer_sizes=400, learning_rate='constant',\n",
        "              learning_rate_init=0.01, max_fun=15000, max_iter=300,\n",
        "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
        "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
        "              warm_start=False)\n",
        "  mlp.fit(X_train,y_train)\n",
        "  scores[x]=mlp.score(X_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration number : 0.15\n",
            "iteration number : 0.16\n",
            "iteration number : 0.17\n",
            "iteration number : 0.18000000000000002\n",
            "iteration number : 0.19000000000000003\n",
            "iteration number : 0.20000000000000004\n",
            "iteration number : 0.21000000000000005\n",
            "iteration number : 0.22000000000000006\n",
            "iteration number : 0.23000000000000007\n",
            "iteration number : 0.24000000000000007\n",
            "iteration number : 0.2500000000000001\n",
            "iteration number : 0.2600000000000001\n",
            "iteration number : 0.27000000000000013\n",
            "iteration number : 0.28000000000000014\n",
            "iteration number : 0.29000000000000015\n",
            "iteration number : 0.30000000000000016\n",
            "iteration number : 0.31000000000000016\n",
            "iteration number : 0.3200000000000002\n",
            "iteration number : 0.3300000000000002\n",
            "iteration number : 0.3400000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "ccSPqZ1nnNu1",
        "outputId": "1c06978a-e898-47a0-a848-eb2f0d681e95"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "list(scores.keys())\n",
        "plt.plot(list(scores.keys()),list(scores.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6f612dbc10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr4SHrdqryZm"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(training_reduced_scale, training_reduced.Y, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RymJ0ynoGnCK"
      },
      "source": [
        "### Random forest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSoBY1iq905X",
        "outputId": "a5b2f9f4-c54d-444c-c4ba-e66f2be1e0b2"
      },
      "source": [
        "RF =  RandomForestClassifier(n_estimators= 1000, min_samples_leaf= 1, min_samples_split= 2)\n",
        "RF.fit(W_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wo27uWp9073",
        "outputId": "3b2deec3-ab18-4f0c-918c-b88e95534cf0"
      },
      "source": [
        "RF.score(W_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.875609190067301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "b49wOVM1J9Zr",
        "outputId": "b129ecec-09c2-4eb1-ad28-72635c208098"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# get importance\n",
        "importance = RF.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "plt.bar([x for x in range(len(importance))], importance)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature: 0, Score: 0.00537\n",
            "Feature: 1, Score: 0.02672\n",
            "Feature: 2, Score: 0.00577\n",
            "Feature: 3, Score: 0.00806\n",
            "Feature: 4, Score: 0.00263\n",
            "Feature: 5, Score: 0.00420\n",
            "Feature: 6, Score: 0.01872\n",
            "Feature: 7, Score: 0.03665\n",
            "Feature: 8, Score: 0.00858\n",
            "Feature: 9, Score: 0.00923\n",
            "Feature: 10, Score: 0.02914\n",
            "Feature: 11, Score: 0.00151\n",
            "Feature: 12, Score: 0.00257\n",
            "Feature: 13, Score: 0.00617\n",
            "Feature: 14, Score: 0.00674\n",
            "Feature: 15, Score: 0.07153\n",
            "Feature: 16, Score: 0.01232\n",
            "Feature: 17, Score: 0.10831\n",
            "Feature: 18, Score: 0.21048\n",
            "Feature: 19, Score: 0.00644\n",
            "Feature: 20, Score: 0.02001\n",
            "Feature: 21, Score: 0.07267\n",
            "Feature: 22, Score: 0.04958\n",
            "Feature: 23, Score: 0.00481\n",
            "Feature: 24, Score: 0.00615\n",
            "Feature: 25, Score: 0.01237\n",
            "Feature: 26, Score: 0.00850\n",
            "Feature: 27, Score: 0.24477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFSecYS0KXXT"
      },
      "source": [
        "# get importance\n",
        "importance = RF.feature_importances_\n",
        "L_importance = []\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "    if v >= 0.02:\n",
        "        L_importance.append(i)\n",
        "\t  #print('Feature: %0d, Score: %.5f' % (i,v))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef_iakMWKpOe"
      },
      "source": [
        "X_train_bis = X_train[L_importance]\n",
        "X_test_bis = X_test[L_importance]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbmyccFcgzQo"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=10)\n",
        "principalComponents_train = pca.fit_transform(X_train)\n",
        "principalComponents_test = pca.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhwWmIA0c6HS"
      },
      "source": [
        "from sklearn.decomposition import NMF\n",
        "model_nmf = NMF(n_components=15, init='random', random_state=0)\n",
        "W_train = model_nmf.fit_transform(X_train)\n",
        "W_test = model_nmf.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jX9BdO890-C",
        "outputId": "d138cdcc-562c-4387-b314-982470385478"
      },
      "source": [
        "#hyperparameter grid search for randomforest\n",
        "n_estimators = [1000,1500]\n",
        "max_depth = [5,10,15]\n",
        "min_samples_split = [2,3,4]\n",
        "min_samples_leaf = [1,2,5]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "hyperF = dict(n_estimators = n_estimators, \n",
        "              min_samples_split = min_samples_split,\n",
        "             min_samples_leaf = min_samples_leaf)\n",
        "clf = GridSearchCV(RandomForestClassifier(), hyperF, cv = 3, verbose = 10,\n",
        "                      n_jobs = -1, scoring='f1_weighted')\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "clf_best = clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 11.9min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 28.0min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 38.7min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 49.4min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 61.8min\n",
            "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed: 71.8min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cok7NSi72xwv",
        "outputId": "8f05002e-8299-4493-e216-9933948122a1"
      },
      "source": [
        "clf_best.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9722199658841686"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfgizj2UJoR8",
        "outputId": "796ba689-b4e4-423b-d38b-9f41cb616d00"
      },
      "source": [
        "clf_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZUxq1baV3Dy"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "cross_val_score(clf_best, X_train, y_train, cv=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CKAaMf_91Ao",
        "outputId": "8f328f14-e3a5-444b-a30e-1431bccaa397"
      },
      "source": [
        "clf_best.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9733116732420515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWjJ2g1AGqk-"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQsfrAm491DI"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUDEHCXWG_DM",
        "outputId": "4e462861-f5fe-4fb5-aa39-94d0ef9d785a"
      },
      "source": [
        "lr.param_grid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'min_samples_leaf': [1, 2, 3, 6],\n",
              " 'min_samples_split': [2, 3, 4, 6],\n",
              " 'n_estimators': [100, 200, 400, 600, 800, 1000]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyM0JC-pGuuq",
        "outputId": "a43870cc-6d97-44f0-877b-f4fe542b4bc1"
      },
      "source": [
        "#hyperparameter grid search for logisticregression\n",
        "tolerance = [1e-7, 1e-6, 1e-5]\n",
        "max_iter = [100, 200, 300, 400]\n",
        "regularization = [0.75, 0.9, 1]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "hyperLR = dict(tol = tolerance, \n",
        "              max_iter = max_iter,\n",
        "             C = regularization)\n",
        "lr = GridSearchCV(LogisticRegression(), hyperLR, cv = 4, verbose = 1,\n",
        "                      n_jobs = -1, scoring='accuracy')\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "lr_best = lr.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:   41.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ZRs38IVcjw",
        "outputId": "8cf3c399-53a4-4dad-bb65-f5417de3dac9"
      },
      "source": [
        "lr_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=1e-07, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewcjWqBB91H9",
        "outputId": "4ebf224f-ef91-48fb-d426-ecfc6cd647ed"
      },
      "source": [
        "lr_best.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.942441590592604"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPUkfjo2V3Hz"
      },
      "source": [
        "### XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyJFX--JGA1C",
        "outputId": "8a8036dd-951e-4356-f145-f41d33a55db4"
      },
      "source": [
        "#hyperparameter grid search for randomforest\n",
        "n_estimators = [200, 400, 600, 800, 1000]\n",
        "max_depth = [5, 10, 15]\n",
        "min_samples_split = [2,4,6]\n",
        "min_samples_leaf = [1, 3, 6]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "hyperF = dict(n_estimators = n_estimators, \n",
        "              min_samples_split = min_samples_split,\n",
        "             min_samples_leaf = min_samples_leaf)\n",
        "xgb = GridSearchCV(XGBClassifier(), hyperF, cv = 5, verbose = 1,\n",
        "                      n_jobs = -1, scoring='accuracy')\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_best = xgb.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 50.4min\n",
            "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed: 58.4min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7kZoJGo7X4z",
        "outputId": "96ba5ea0-6800-44f0-9002-5111fab7b324"
      },
      "source": [
        "xgb_best.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9750889679715302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I--_2dPD91K4",
        "outputId": "7dc84ecf-0d1c-4623-8afa-1463b8e7a2f4"
      },
      "source": [
        "xgb= XGBClassifier(n_estimators=1000)\n",
        "xgb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0vxUn_FxVr4"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02SBMYHANV1j"
      },
      "source": [
        "#hyperparameter grid search for randomforest\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "hyperF = dict(n_estimators = n_estimators, \n",
        "              min_samples_split = min_samples_split,\n",
        "             min_samples_leaf = min_samples_leaf)\n",
        "dt = GridSearchCV(DecisionTreeClassifier(), hyperF, cv = 3, verbose = 1,\n",
        "                      n_jobs = -1, scoring='accuracy')\n",
        "\n",
        "dt.fit(X_test, y_test)\n",
        "dt_best = dt.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DboCgrHk-G9w",
        "outputId": "43bf1dd2-49f0-4b42-d0f2-8e3ce533a6eb"
      },
      "source": [
        "dt.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9610118356927362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfkzIzEn-G0y",
        "outputId": "10c7b15e-72d8-4314-aefc-5e36bdb97439"
      },
      "source": [
        "dt= DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfLCBuukxYtV"
      },
      "source": [
        "### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gh2PZzj-HCK",
        "outputId": "6ef65367-f673-4d1e-a27a-44d74b49ab85"
      },
      "source": [
        "\n",
        "svc= SVC()\n",
        "svc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsyBjouo-HFE",
        "outputId": "3ec83d59-d507-46bd-f6bd-4c45d2eb594c"
      },
      "source": [
        "svc.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9591552564400093"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWc-j1fO-HHY",
        "outputId": "0e3d39ad-6a5d-487e-d6e4-b091d32746ec"
      },
      "source": [
        "lsvc= LinearSVC()\n",
        "lsvc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByVHYik1-HKQ",
        "outputId": "8d95b094-ffd6-43e9-ae9a-487c3116e0ec"
      },
      "source": [
        "lsvc.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9589231840334185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBv_7BKOxa8y"
      },
      "source": [
        "### Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXEXMNh--HMw",
        "outputId": "0a04ced3-3ae3-40a7-a5c8-b3d40ff0251b"
      },
      "source": [
        "et=ExtraTreesClassifier(n_estimators=1000)\n",
        "et.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                     criterion='gini', max_depth=None, max_features='auto',\n",
              "                     max_leaf_nodes=None, max_samples=None,\n",
              "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                     min_samples_leaf=1, min_samples_split=2,\n",
              "                     min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
              "                     warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeKJ-dMX-HPX",
        "outputId": "2b6cc13a-44f6-4f70-b6f8-c0912528c049"
      },
      "source": [
        "et.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9729635646321653"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCSPtqWcxdrm"
      },
      "source": [
        "### Gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te0dntdm-HRu",
        "outputId": "46be93d2-e263-4e90-b979-cca8d34ff49d"
      },
      "source": [
        "gb=GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICq9MLXV-HUR",
        "outputId": "c9d172d3-c47d-4df1-e8a4-68e9171ea279"
      },
      "source": [
        "gb.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9745880714783012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn_jm5SPxgcX"
      },
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dRHPkxw-HW4",
        "outputId": "1c4a792c-5970-41a3-a9e3-9ef91d1ce0de"
      },
      "source": [
        "ab=AdaBoostClassifier(n_estimators=1000, learning_rate=0.8)\n",
        "ab.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.8,\n",
              "                   n_estimators=1000, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5zHW5dz-HZZ",
        "outputId": "3f7c7c90-0cf3-4dd9-8170-131deaf6a2fa"
      },
      "source": [
        "ab.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9707588767695521"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_swF2OCPwOS"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "ada=AdaBoostClassifier()\n",
        "search_grid={'n_estimators':[500,1000,2000],'learning_rate':[.1,0.3,.5]}\n",
        "search=GridSearchCV(estimator=ada,param_grid=search_grid,scoring='f1_micro',cv=3,verbose=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQAjrtznP-9O",
        "outputId": "1f7236c8-6075-4bca-c17a-b3300831537a"
      },
      "source": [
        "search.fit(X_train,y_train)\n",
        "clf_best = search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "[CV] learning_rate=0.001, n_estimators=500 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=500, score=0.960, total=  25.1s\n",
            "[CV] learning_rate=0.001, n_estimators=500 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=500, score=0.958, total=  25.1s\n",
            "[CV] learning_rate=0.001, n_estimators=500 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   50.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=500, score=0.956, total=  25.1s\n",
            "[CV] learning_rate=0.001, n_estimators=1000 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.3min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=1000, score=0.960, total=  50.3s\n",
            "[CV] learning_rate=0.001, n_estimators=1000 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.1min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=1000, score=0.958, total=  50.0s\n",
            "[CV] learning_rate=0.001, n_estimators=1000 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.9min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=1000, score=0.957, total=  50.0s\n",
            "[CV] learning_rate=0.001, n_estimators=2000 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=2000, score=0.963, total= 1.7min\n",
            "[CV] learning_rate=0.001, n_estimators=2000 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  5.5min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=2000, score=0.959, total= 1.7min\n",
            "[CV] learning_rate=0.001, n_estimators=2000 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  7.1min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.001, n_estimators=2000, score=0.959, total= 1.6min\n",
            "[CV] learning_rate=0.01, n_estimators=500 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  8.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  learning_rate=0.01, n_estimators=500, score=0.966, total=  24.9s\n",
            "[CV] learning_rate=0.01, n_estimators=500 ............................\n",
            "[CV]  learning_rate=0.01, n_estimators=500, score=0.962, total=  24.9s\n",
            "[CV] learning_rate=0.01, n_estimators=500 ............................\n",
            "[CV]  learning_rate=0.01, n_estimators=500, score=0.962, total=  24.8s\n",
            "[CV] learning_rate=0.01, n_estimators=1000 ...........................\n",
            "[CV]  learning_rate=0.01, n_estimators=1000, score=0.971, total=  49.5s\n",
            "[CV] learning_rate=0.01, n_estimators=1000 ...........................\n",
            "[CV]  learning_rate=0.01, n_estimators=1000, score=0.968, total=  49.4s\n",
            "[CV] learning_rate=0.01, n_estimators=1000 ...........................\n",
            "[CV]  learning_rate=0.01, n_estimators=1000, score=0.967, total=  49.4s\n",
            "[CV] learning_rate=0.01, n_estimators=2000 ...........................\n",
            "[CV]  learning_rate=0.01, n_estimators=2000, score=0.973, total= 1.6min\n",
            "[CV] learning_rate=0.01, n_estimators=2000 ...........................\n",
            "[CV]  learning_rate=0.01, n_estimators=2000, score=0.971, total= 1.6min\n",
            "[CV] learning_rate=0.01, n_estimators=2000 ...........................\n",
            "[CV]  learning_rate=0.01, n_estimators=2000, score=0.969, total= 1.6min\n",
            "[CV] learning_rate=0.1, n_estimators=500 .............................\n",
            "[CV] . learning_rate=0.1, n_estimators=500, score=0.974, total=  24.7s\n",
            "[CV] learning_rate=0.1, n_estimators=500 .............................\n",
            "[CV] . learning_rate=0.1, n_estimators=500, score=0.972, total=  24.4s\n",
            "[CV] learning_rate=0.1, n_estimators=500 .............................\n",
            "[CV] . learning_rate=0.1, n_estimators=500, score=0.970, total=  24.2s\n",
            "[CV] learning_rate=0.1, n_estimators=1000 ............................\n",
            "[CV]  learning_rate=0.1, n_estimators=1000, score=0.974, total=  49.1s\n",
            "[CV] learning_rate=0.1, n_estimators=1000 ............................\n",
            "[CV]  learning_rate=0.1, n_estimators=1000, score=0.974, total=  49.5s\n",
            "[CV] learning_rate=0.1, n_estimators=1000 ............................\n",
            "[CV]  learning_rate=0.1, n_estimators=1000, score=0.971, total=  49.5s\n",
            "[CV] learning_rate=0.1, n_estimators=2000 ............................\n",
            "[CV]  learning_rate=0.1, n_estimators=2000, score=0.974, total= 1.7min\n",
            "[CV] learning_rate=0.1, n_estimators=2000 ............................\n",
            "[CV]  learning_rate=0.1, n_estimators=2000, score=0.974, total= 1.7min\n",
            "[CV] learning_rate=0.1, n_estimators=2000 ............................\n",
            "[CV]  learning_rate=0.1, n_estimators=2000, score=0.971, total= 1.7min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 26.1min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN9ffI4WYovE",
        "outputId": "ca6929e7-c55a-42d9-ba86-5a391e96352b"
      },
      "source": [
        "clf_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.1,\n",
              "                   n_estimators=2000, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO52teOKxjuG"
      },
      "source": [
        "### Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn68bPNy-HcE",
        "outputId": "700b4500-1308-4c7d-f613-777dd9243725"
      },
      "source": [
        "#stacking classifiers\n",
        "\n",
        "base_learners = [\n",
        "              #   ('lr', LogisticRegression()),\n",
        "                 ('xgb', xgb_best),\n",
        "                 ('rf', clf_best)\n",
        "                     \n",
        "                ]\n",
        "stc = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression())\n",
        "stc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(cv=None,\n",
              "                   estimators=[('xgb',\n",
              "                                XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                              colsample_bylevel=1,\n",
              "                                              colsample_bynode=1,\n",
              "                                              colsample_bytree=1, gamma=0,\n",
              "                                              learning_rate=0.1,\n",
              "                                              max_delta_step=0, max_depth=3,\n",
              "                                              min_child_weight=1,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2, missing=None,\n",
              "                                              n_estimators=400, n_jobs=1,\n",
              "                                              nthread=None,\n",
              "                                              objective='binary:logistic',\n",
              "                                              random_...\n",
              "                                                       random_state=None,\n",
              "                                                       verbose=0,\n",
              "                                                       warm_start=False))],\n",
              "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                      dual=False,\n",
              "                                                      fit_intercept=True,\n",
              "                                                      intercept_scaling=1,\n",
              "                                                      l1_ratio=None,\n",
              "                                                      max_iter=100,\n",
              "                                                      multi_class='auto',\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      random_state=None,\n",
              "                                                      solver='lbfgs',\n",
              "                                                      tol=0.0001, verbose=0,\n",
              "                                                      warm_start=False),\n",
              "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
              "                   verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddNKrh3F-Hg7",
        "outputId": "ec0a5bc6-1827-44f0-a187-80c84a644b5a"
      },
      "source": [
        "stc.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9785333023903457"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IQM-igv0Bn_"
      },
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArBm1Xme0EAL"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-3FoYRd0F9M",
        "outputId": "6ba44c53-132b-4e9a-a90b-b623e59e18d3"
      },
      "source": [
        "mlp = MLPClassifier(random_state=1, max_iter=300)\n",
        "mlp.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-qQ6P3GZhMA",
        "outputId": "4127bda5-c738-4e58-c836-e33df9960d18"
      },
      "source": [
        "mlp.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9720575095443099"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_yq2iGZqKZF4",
        "outputId": "2dddd965-33bb-47b2-dcf6-e44164859f50"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "mlp.f1_score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-bf38e1dd0cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'f1_score'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS8vM-WXaqQW",
        "outputId": "4c0868c0-aea6-4fed-cbd4-e0ce6b63a5c1"
      },
      "source": [
        "mlp = MLPClassifier(activation='relu', alpha=1e-05, batch_size=100, beta_1=0.9,\n",
        "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "              hidden_layer_sizes=200, learning_rate='constant',\n",
        "              learning_rate_init=0.01, max_fun=15000, max_iter=500,\n",
        "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
        "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
        "              warm_start=False)\n",
        "\n",
        "mlp.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size=100, beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.01, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Suyjy5tLTP6",
        "outputId": "6d312fb1-7fc0-4e6d-bbdd-409e67109d26"
      },
      "source": [
        "mlp.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9714550939893246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pTtF5_zXtuj",
        "outputId": "2ff9ab03-a623-4420-b9de-e170c144db6c"
      },
      "source": [
        "mlp = MLPClassifier(activation='relu', alpha=1e-06, batch_size=100, beta_1=0.9,\n",
        "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "              hidden_layer_sizes=200, learning_rate='constant',\n",
        "              learning_rate_init=0.01, max_fun=15000, max_iter=1000,\n",
        "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
        "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
        "              warm_start=False)\n",
        "mlp.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-06, batch_size=100, beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.01, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuyj6o_IXtzB",
        "outputId": "6faf1d39-cf43-43a6-b34c-e3579d3f2256"
      },
      "source": [
        "mlp.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.973032247583462"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu5DHJkVYVFt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hy0Hig421na",
        "outputId": "6bd315da-7d1f-4f2b-9695-227ef70f4dc6"
      },
      "source": [
        "#hyperparameter grid search for randomforest\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "learning_rate_init = [1e-3, 1e-2,1e-4]\n",
        "alpha = [1e-5, 1e-4,1e-6]\n",
        "hidden_layer_sizes = [200,400,600,800]\n",
        "activation= ['tanh', 'relu']\n",
        "solver=['sgd', 'adam']\n",
        "\n",
        "\n",
        "\n",
        "hypermlp = dict(learning_rate_init = learning_rate_init,\n",
        "                alpha = alpha,\n",
        "                hidden_layer_sizes = hidden_layer_sizes,\n",
        "                activation = activation,\n",
        "                solver = solver)\n",
        "\n",
        "    \n",
        "mlp = GridSearchCV(MLPClassifier(random_state=1, max_iter=300), hypermlp, cv = 3, verbose = 10,\n",
        "                      n_jobs = -1, scoring='f1_weighted')\n",
        "\n",
        "mlp.fit(X_test, y_test)\n",
        "mlp_best = mlp.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8ee882b7c837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m mlp = GridSearchCV(MLPClassifier(random_state=1, max_iter=300), hypermlp, cv = 3, verbose = 10,\n\u001b[0m\u001b[1;32m     22\u001b[0m                       n_jobs = -1, scoring='f1_weighted')\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cMso1lgPJQff",
        "outputId": "0afc2db7-43a6-4781-fdec-1a3e8971abcd"
      },
      "source": [
        "mlp_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=600, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EVXQHeS10Qec",
        "outputId": "72f11c47-9654-4e9b-94fc-469ddc80f067"
      },
      "source": [
        "mlp_best.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9743312032925376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "HY1ikVdM2YP-",
        "outputId": "34fea6b4-dc80-4342-d1fe-b56901f9ee04"
      },
      "source": [
        "mlp=MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
        "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "              hidden_layer_sizes=[200,200], learning_rate='constant',\n",
        "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
        "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
        "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
        "              warm_start=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b8953e2e87f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mlp=MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mlearning_rate_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_no_change\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterovs_momentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD7jPaco2YTM",
        "outputId": "239959ad-db44-4e70-f683-c53d51128dd4"
      },
      "source": [
        "mlp.fit(X_train,y_train)\n",
        "mlp.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9684826167009639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jasp8ZXK0osN"
      },
      "source": [
        "### Gaussian process classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSUC3ohW0qjV"
      },
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G07SaebT0rgO"
      },
      "source": [
        "kernel = 1.0 * RBF(1.0)\n",
        "gpc = GaussianProcessClassifier(kernel=kernel,random_state=0)\n",
        "gpc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "NxkngDXd07gL",
        "outputId": "1d383ceb-c83a-4641-e995-061bd0101b1f"
      },
      "source": [
        "gpc.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61ceafcddd92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gpc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGCBXhuG1ob3"
      },
      "source": [
        "### Gaussian NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXsMGwXP1zfW"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYNxwhII10wK",
        "outputId": "62ec94f1-f5b5-41b2-c46f-94b732540315"
      },
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBsV6ASd17tN",
        "outputId": "77f0511a-9dd5-4ecf-8f5f-7a3f6e6eb558"
      },
      "source": [
        "gnb.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9448828034346716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v4u_v_g1_vm"
      },
      "source": [
        "### Quadratic discriminant analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BP3uE6p2F9o"
      },
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkVeE6Zf2N0q",
        "outputId": "5abbd37b-8279-4445-b54f-7c768b7a57f2"
      },
      "source": [
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
              "                              store_covariance=False, tol=0.0001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB41vjw22Udw",
        "outputId": "2bcb3c47-aa81-44a6-8bd7-bb4366745015"
      },
      "source": [
        "qda.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9454629844511487"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if0l2FIP2dn6"
      },
      "source": [
        "### K neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pLxfB0I2gBG"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljBY7cfI2hlM",
        "outputId": "6719f9fb-842f-477a-ba4a-eb6c92b2147a"
      },
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16RFS8y22muv",
        "outputId": "bc0d0eb4-1030-4bc9-bc82-80c4796ac857"
      },
      "source": [
        "neigh.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9270132281271757"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeR3cLO02u8x"
      },
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkh3GfxB3uoR"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf_best = MLPClassifier(activation='relu', alpha=1e-07, batch_size=140, beta_1=0.9,\n",
        "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "              learning_rate_init=0.001, max_fun=15000, max_iter=800,\n",
        "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
        "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
        "              warm_start=False)\n",
        "\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf06mqFf-HkF"
      },
      "source": [
        "\n",
        "#writing predictions to csv\n",
        "\n",
        "predictions = list(clf_best.predict(testing_scale))\n",
        "pred_df = pd.DataFrame(predictions,columns =['category'])\n",
        "pred_df.index.names = ['id']\n",
        "#pred_df.to_csv('predictions_RFgridsearch_fullfeatures_scaled.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOwL8jPX-HqD"
      },
      "source": [
        "pred_df.to_csv(path+'predictions_mlp.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_71iqMC9-Hsh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}